"""
å½±åƒè™•ç†å’ŒYOLOv12æ¨è«–æ¨¡çµ„
è² è²¬å½±åƒå‰è™•ç†ã€é‚Šç·£æª¢æ¸¬ã€æ¿¾æ³¢å¢å¼·å’ŒYOLOç‰©ä»¶åµæ¸¬
"""

import cv2
import numpy as np
import time
from typing import Tuple, List, Dict, Optional
from dataclasses import dataclass

try:
    # å˜—è©¦å°å…¥YOLOv8 (ultralyticså¥—ä»¶ï¼ŒåŒ…å«YOLOv12)
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    print("âœ… YOLOv12/ultralytics å¯ç”¨")
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ YOLOv12/ultralytics æœªå®‰è£ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨è«–")

@dataclass
class DetectionResult:
    """æª¢æ¸¬çµæœæ•¸æ“šé¡"""
    class_id: int
    class_name: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2
    center: Tuple[int, int]

@dataclass
class ProcessingConfig:
    """å½±åƒè™•ç†é…ç½®"""
    # é‚Šç·£æª¢æ¸¬åƒæ•¸
    canny_low: int = 50
    canny_high: int = 150
    canny_aperture: int = 3
    
    # é«˜æ–¯æ¿¾æ³¢åƒæ•¸
    gaussian_kernel: int = 5
    gaussian_sigma: float = 1.0
    
    # å°æ¯”åº¦å¢å¼·åƒæ•¸
    contrast_alpha: float = 1.5  # å°æ¯”åº¦å¢å¼·å› å­
    brightness_beta: int = 10    # äº®åº¦èª¿æ•´
    
    # YOLOæ¨è«–åƒæ•¸
    yolo_confidence: float = 0.5  # ä¿¡å¿ƒé–¾å€¼
    yolo_iou: float = 0.4        # NMS IoUé–¾å€¼
    yolo_max_detections: int = 10 # æœ€å¤§æª¢æ¸¬æ•¸é‡
    
    # é¡¯ç¤ºåƒæ•¸
    show_edges: bool = True       # é¡¯ç¤ºé‚Šç·£
    show_enhanced: bool = True    # é¡¯ç¤ºå¢å¼·å¾Œå½±åƒ
    show_detections: bool = True  # é¡¯ç¤ºæª¢æ¸¬çµæœ

class ImageProcessor:
    """å½±åƒè™•ç†å™¨é¡"""
    
    def __init__(self, model_path: str = "yolov8n.pt"):
        self.config = ProcessingConfig()
        self.yolo_model = None
        self.model_path = model_path
        self.processing_stats = {
            'frame_count': 0,
            'processing_time': 0.0,
            'inference_time': 0.0
        }
        
        # PCBAç›¸é—œé¡åˆ¥åç¨± (å¯è‡ªå®šç¾©)
        self.pcba_classes = {
            0: 'pcb',           # å°åˆ·é›»è·¯æ¿
            1: 'component',     # é›»å­å…ƒä»¶
            2: 'connector',     # é€£æ¥å™¨
            3: 'capacitor',     # é›»å®¹
            4: 'resistor',      # é›»é˜»
            5: 'ic',           # ç©é«”é›»è·¯
            6: 'defect',       # ç¼ºé™·
            7: 'short',        # çŸ­è·¯
            8: 'missing',      # ç¼ºä»¶
            9: 'bridge'        # æ©‹æ¥
        }
        
        self.init_yolo_model()
    
    def init_yolo_model(self):
        """åˆå§‹åŒ–YOLOæ¨¡å‹"""
        if not YOLO_AVAILABLE:
            print("âš ï¸ YOLOæ¨¡çµ„ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨è«–")
            return
            
        try:
            # è¼‰å…¥YOLOv12æ¨¡å‹ (å¦‚æœæœ‰) æˆ– YOLOv8
            print(f"ğŸ”„ è¼‰å…¥YOLOæ¨¡å‹: {self.model_path}")
            self.yolo_model = YOLO(self.model_path)
            
            # æš–æ©Ÿé‹è¡Œ
            dummy_image = np.zeros((640, 640, 3), dtype=np.uint8)
            _ = self.yolo_model.predict(dummy_image, verbose=False)
            
            print("âœ… YOLOæ¨¡å‹è¼‰å…¥æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ YOLOæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            self.yolo_model = None
    
    def apply_edge_detection(self, image: np.ndarray) -> np.ndarray:
        """
        é‚Šç·£æª¢æ¸¬è™•ç†
        
        Args:
            image: è¼¸å…¥å½±åƒ
            
        Returns:
            é‚Šç·£æª¢æ¸¬çµæœ
        """
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # é«˜æ–¯æ¨¡ç³Šé™å™ª
        blurred = cv2.GaussianBlur(
            gray, 
            (self.config.gaussian_kernel, self.config.gaussian_kernel),
            self.config.gaussian_sigma
        )
        
        # Cannyé‚Šç·£æª¢æ¸¬
        edges = cv2.Canny(
            blurred,
            self.config.canny_low,
            self.config.canny_high,
            apertureSize=self.config.canny_aperture
        )
        
        # è½‰æ›ç‚ºä¸‰é€šé“ä»¥ä¾¿é¡¯ç¤º
        edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        
        return edges_colored
    
    def apply_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        å½±åƒå¢å¼·è™•ç† (å°æ¯”åº¦ã€äº®åº¦ã€éŠ³åŒ–)
        
        Args:
            image: è¼¸å…¥å½±åƒ
            
        Returns:
            å¢å¼·å¾Œå½±åƒ
        """
        # å°æ¯”åº¦å’Œäº®åº¦èª¿æ•´
        enhanced = cv2.convertScaleAbs(
            image, 
            alpha=self.config.contrast_alpha, 
            beta=self.config.brightness_beta
        )
        
        # éŠ³åŒ–æ¿¾æ³¢å™¨
        sharpening_kernel = np.array([
            [-1, -1, -1],
            [-1,  9, -1], 
            [-1, -1, -1]
        ])
        
        # æ‡‰ç”¨éŠ³åŒ–
        sharpened = cv2.filter2D(enhanced, -1, sharpening_kernel)
        
        # é«˜æ–¯æ¿¾æ³¢å¹³æ»‘
        smoothed = cv2.GaussianBlur(
            sharpened,
            (self.config.gaussian_kernel, self.config.gaussian_kernel),
            self.config.gaussian_sigma
        )
        
        return smoothed
    
    def run_yolo_inference(self, image: np.ndarray) -> Tuple[np.ndarray, List[DetectionResult]]:
        """
        é‹è¡ŒYOLOv12æ¨è«–
        
        Args:
            image: è¼¸å…¥å½±åƒ
            
        Returns:
            (å¸¶æª¢æ¸¬æ¡†çš„å½±åƒ, æª¢æ¸¬çµæœåˆ—è¡¨)
        """
        start_time = time.time()
        
        if not self.yolo_model:
            # æ¨¡æ“¬æ¨è«–çµæœ
            return self._simulate_yolo_inference(image)
        
        try:
            # YOLOv12æ¨è«–
            results = self.yolo_model.predict(
                image,
                conf=self.config.yolo_confidence,
                iou=self.config.yolo_iou,
                max_det=self.config.yolo_max_detections,
                verbose=False
            )
            
            # è™•ç†æª¢æ¸¬çµæœ
            detections = []
            annotated_image = image.copy()
            
            if results and len(results) > 0:
                result = results[0]  # å–ç¬¬ä¸€å€‹çµæœ
                
                # ç²å–æª¢æ¸¬æ¡†
                if result.boxes is not None:
                    boxes = result.boxes.cpu().numpy()
                    
                    for box in boxes:
                        # åº§æ¨™å’Œä¿¡å¿ƒåº¦
                        x1, y1, x2, y2 = box.xyxy[0].astype(int)
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        
                        # é¡åˆ¥åç¨±
                        class_name = self.pcba_classes.get(class_id, f"class_{class_id}")
                        
                        # ä¸­å¿ƒé»
                        center_x = int((x1 + x2) / 2)
                        center_y = int((y1 + y2) / 2)
                        
                        # å‰µå»ºæª¢æ¸¬çµæœ
                        detection = DetectionResult(
                            class_id=class_id,
                            class_name=class_name,
                            confidence=confidence,
                            bbox=(x1, y1, x2, y2),
                            center=(center_x, center_y)
                        )
                        detections.append(detection)
                        
                        # ç¹ªè£½æª¢æ¸¬æ¡†
                        if self.config.show_detections:
                            self._draw_detection(annotated_image, detection)
            
            self.processing_stats['inference_time'] = time.time() - start_time
            
            return annotated_image, detections
            
        except Exception as e:
            print(f"YOLOæ¨è«–éŒ¯èª¤: {e}")
            return self._simulate_yolo_inference(image)
    
    def _simulate_yolo_inference(self, image: np.ndarray) -> Tuple[np.ndarray, List[DetectionResult]]:
        """
        æ¨¡æ“¬YOLOv12æ¨è«– (ç”¨æ–¼æ¸¬è©¦)
        """
        annotated_image = image.copy()
        detections = []
        
        # æ¨¡æ“¬ä¸€äº›æª¢æ¸¬çµæœ
        h, w = image.shape[:2]
        
        # æ¨¡æ“¬PCBæª¢æ¸¬
        if np.random.random() > 0.3:
            detection = DetectionResult(
                class_id=0,
                class_name='pcb',
                confidence=0.85 + np.random.random() * 0.1,
                bbox=(w//4, h//4, 3*w//4, 3*h//4),
                center=(w//2, h//2)
            )
            detections.append(detection)
            self._draw_detection(annotated_image, detection)
        
        # æ¨¡æ“¬å…ƒä»¶æª¢æ¸¬
        for _ in range(np.random.randint(1, 4)):
            x1 = np.random.randint(0, w//2)
            y1 = np.random.randint(0, h//2)
            x2 = x1 + np.random.randint(50, 150)
            y2 = y1 + np.random.randint(30, 100)
            
            x2 = min(x2, w-1)
            y2 = min(y2, h-1)
            
            detection = DetectionResult(
                class_id=1,
                class_name='component',
                confidence=0.6 + np.random.random() * 0.3,
                bbox=(x1, y1, x2, y2),
                center=((x1+x2)//2, (y1+y2)//2)
            )
            detections.append(detection)
            self._draw_detection(annotated_image, detection)
        
        return annotated_image, detections
    
    def _draw_detection(self, image: np.ndarray, detection: DetectionResult):
        """åœ¨å½±åƒä¸Šç¹ªè£½æª¢æ¸¬çµæœ"""
        x1, y1, x2, y2 = detection.bbox
        
        # æ ¹æ“šé¡åˆ¥é¸æ“‡é¡è‰²
        color_map = {
            'pcb': (0, 255, 0),        # ç¶ è‰²
            'component': (255, 0, 0),   # è—è‰²
            'defect': (0, 0, 255),      # ç´…è‰²
            'short': (0, 0, 255),       # ç´…è‰²
            'missing': (0, 165, 255),   # æ©™è‰²
            'bridge': (0, 255, 255)     # é»ƒè‰²
        }
        
        color = color_map.get(detection.class_name, (128, 128, 128))
        
        # ç¹ªè£½æª¢æ¸¬æ¡†
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # ç¹ªè£½æ¨™ç±¤
        label = f"{detection.class_name}: {detection.confidence:.2f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
        
        # æ¨™ç±¤èƒŒæ™¯
        cv2.rectangle(
            image, 
            (x1, y1 - label_size[1] - 10), 
            (x1 + label_size[0], y1), 
            color, 
            -1
        )
        
        # æ¨™ç±¤æ–‡å­—
        cv2.putText(
            image, 
            label, 
            (x1, y1 - 5), 
            cv2.FONT_HERSHEY_SIMPLEX, 
            0.5, 
            (255, 255, 255), 
            1
        )
        
        # ç¹ªè£½ä¸­å¿ƒé»
        center_x, center_y = detection.center
        cv2.circle(image, (center_x, center_y), 3, color, -1)
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, np.ndarray, List[DetectionResult]]:
        """
        è™•ç†å–®å¹€å½±åƒ
        
        Args:
            frame: åŸå§‹å½±åƒå¹€
            
        Returns:
            (é‚Šç·£æª¢æ¸¬å½±åƒ, YOLOæ¨è«–å½±åƒ, æª¢æ¸¬çµæœ)
        """
        start_time = time.time()
        
        if frame is None:
            # è¿”å›ç©ºå½±åƒ
            empty = np.zeros((480, 640, 3), dtype=np.uint8)
            return empty, empty, []
        
        # 1. é‚Šç·£æª¢æ¸¬è™•ç†
        edges_image = self.apply_edge_detection(frame)
        
        # 2. å½±åƒå¢å¼·
        enhanced_frame = self.apply_enhancement(frame)
        
        # 3. YOLOv12æ¨è«–
        yolo_image, detections = self.run_yolo_inference(enhanced_frame)
        
        # 4. åˆæˆè™•ç†å¾Œå½±åƒ
        processed_image = self._combine_processing_results(
            edges_image, yolo_image
        )
        
        # æ›´æ–°çµ±è¨ˆ
        self.processing_stats['frame_count'] += 1
        self.processing_stats['processing_time'] = time.time() - start_time
        
        return edges_image, processed_image, detections
    
    def _combine_processing_results(self, edges: np.ndarray, yolo_result: np.ndarray) -> np.ndarray:
        """
        åˆæˆè™•ç†çµæœ
        
        Args:
            edges: é‚Šç·£æª¢æ¸¬çµæœ
            yolo_result: YOLOæ¨è«–çµæœ
            
        Returns:
            åˆæˆå½±åƒ
        """
        # æ–¹æ³•1: ç–ŠåŠ é‚Šç·£åˆ°YOLOçµæœ
        if self.config.show_edges:
            # å°‡é‚Šç·£è½‰ç‚ºé®ç½©
            edges_gray = cv2.cvtColor(edges, cv2.COLOR_BGR2GRAY)
            edges_mask = edges_gray > 50
            
            # åœ¨YOLOçµæœä¸Šç–ŠåŠ é‚Šç·£ (ç¶ è‰²)
            combined = yolo_result.copy()
            combined[edges_mask] = [0, 255, 0]  # ç¶ è‰²é‚Šç·£
            
            return combined
        else:
            return yolo_result
    
    def get_processing_stats(self) -> Dict:
        """ç²å–è™•ç†çµ±è¨ˆè³‡è¨Š"""
        fps = 0
        if self.processing_stats['processing_time'] > 0:
            fps = 1.0 / self.processing_stats['processing_time']
            
        return {
            'frame_count': self.processing_stats['frame_count'],
            'processing_time': self.processing_stats['processing_time'],
            'inference_time': self.processing_stats['inference_time'],
            'fps': fps,
            'yolo_available': self.yolo_model is not None
        }
    
    def update_config(self, **kwargs):
        """æ›´æ–°è™•ç†é…ç½®"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                print(f"ğŸ”§ æ›´æ–°é…ç½® {key} = {value}")
    
    def reset_stats(self):
        """é‡è¨­çµ±è¨ˆè³‡è¨Š"""
        self.processing_stats = {
            'frame_count': 0,
            'processing_time': 0.0,
            'inference_time': 0.0
        }


# æ¸¬è©¦å‡½æ•¸
def test_image_processor():
    """æ¸¬è©¦å½±åƒè™•ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦å½±åƒè™•ç†å™¨...")
    
    processor = ImageProcessor()
    
    # å‰µå»ºæ¸¬è©¦å½±åƒ
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # è™•ç†å½±åƒ
    edges, processed, detections = processor.process_frame(test_image)
    
    print(f"âœ… é‚Šç·£æª¢æ¸¬å½±åƒå°ºå¯¸: {edges.shape}")
    print(f"âœ… è™•ç†å¾Œå½±åƒå°ºå¯¸: {processed.shape}")
    print(f"âœ… æª¢æ¸¬åˆ° {len(detections)} å€‹ç‰©ä»¶")
    
    # é¡¯ç¤ºçµ±è¨ˆ
    stats = processor.get_processing_stats()
    print(f"ğŸ“Š è™•ç†çµ±è¨ˆ: {stats}")


if __name__ == '__main__':
    test_image_processor()
